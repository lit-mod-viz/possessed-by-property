{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss objects and libraries\n",
    "# getting to know your objects and what they can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is our model? Characters are agents, that is they act upon themseleves\n",
    "# and others. Characters talk, and own things. Other ideas?\n",
    "\n",
    "# This will need to be shored up theoretically quite a bit, in fact \n",
    "# the main work of the paper. Furthermore, what is the relationaship between the so called \n",
    "# major and minor characters? To really challenge our intutions let's also introduce \n",
    "# Gertrude Stein's Tender Buttons (1914) into the mix, a novel which purpusfully lacks\n",
    "# conventional characters and action, as well as Airport (1968) by the American Author Hailey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the above intutions into *models*. \n",
    "\n",
    "# 1. Grammatical subject of the sentence. Pronouns are a problem. However, we can\n",
    "#    selectively sample named entities. Resolve pronouns in another pass. Let's see if it\n",
    "#   was done.\n",
    "\n",
    "# 2. Who gets to speak. Direct speech. See Moretti on Hamlet and character networks. Co-occurance.\n",
    "#    Network centrality? Actors who are not charachters? Network needs a priori model of agency. Org/place.\n",
    "#    Confined spaces / beeing trapped. Luhmann?\n",
    "#\n",
    "# 3. Ownership through posessives. This one seems easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# let's experiment with a few sentences\n",
    "sample1 = \"\"\" Harris reached for an oxygen line immediately, and a moment \n",
    "             later Cy Jordan pressed the button that gave the passengers \n",
    "             the oxygen they needed. \"\"\"\n",
    "\n",
    "sample1_doc = nlp(sample1)\n",
    "\n",
    "type(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Harris\n",
      "an oxygen line\n",
      "a moment\n",
      "Cy Jordan\n",
      "the button\n",
      "the passengers\n",
      "the oxygen\n",
      "they\n"
     ]
    }
   ],
   "source": [
    "# what kind of object is this and what can we do with it?\n",
    "type(sample1_doc)\n",
    "for chunk in sample1_doc.noun_chunks:\n",
    "    print(chunk)\n",
    "\n",
    "sample1_doc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Harris\n",
      "reached\n",
      "for\n",
      "an\n",
      "oxygen\n",
      "line\n",
      "immediately\n",
      ",\n",
      "and\n",
      "a\n",
      "moment\n",
      "\n",
      "             \n",
      "later\n",
      "Cy\n",
      "Jordan\n",
      "pressed\n",
      "the\n",
      "button\n",
      "that\n",
      "gave\n",
      "the\n",
      "passengers\n",
      "\n",
      "             \n",
      "the\n",
      "oxygen\n",
      "they\n",
      "needed\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in sample1_doc:\n",
    "    print(token)\n",
    "type(token)\n",
    "\n",
    "sample1_doc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Harris\n",
      "an oxygen line\n",
      "a moment\n",
      "Cy Jordan\n",
      "the button\n",
      "the passengers\n",
      "the oxygen\n",
      "they\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chunks = sample1_doc.noun_chunks\n",
    "\n",
    "for chunk in test_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "Harris nsubj\n",
      "reached ROOT\n",
      "for prep\n",
      "an det\n",
      "oxygen compound\n",
      "line pobj\n",
      "immediately advmod\n",
      ", punct\n",
      "and cc\n",
      "a det\n",
      "moment conj\n",
      "\n",
      "              \n",
      "later advmod\n",
      "Cy compound\n",
      "Jordan nsubj\n",
      "pressed conj\n",
      "the det\n",
      "button dobj\n",
      "that nsubj\n",
      "gave relcl\n",
      "the det\n",
      "passengers dative\n",
      "\n",
      "              \n",
      "the det\n",
      "oxygen dobj\n",
      "they nsubj\n",
      "needed relcl\n",
      ". punct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for token in sample1_doc:\n",
    "    print(token, token.dep_)\n",
    "type(token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'determiner'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('det')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-31b293f40955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample1_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'oxygen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "sample1_doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore what these mean\n",
    "# https://spacy.io/usage/linguistic-features\n",
    "# https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which papers to cite in relation to Stanford dependencies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
